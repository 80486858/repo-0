{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AFF3CT-core Developer Documentation","text":""},{"location":"#introduction","title":"Introduction","text":"<p><code>AFF3CT-core</code> is a DSEL for streaming applications written in C++. This  documentation focus on explaining the basic elements of the language from the  developer point of view.</p> <p>Here are the main features of <code>AFF3CT-core</code>:</p> <ul> <li>Definition of modules, tasks and sockets (dataflow)</li> <li>Elementary modules and tasks implementations</li> <li>Parallel runtime (replication, pipeline)</li> </ul> <p>The DSEL is suitable for SDR systems, video processing and more generally it  matches single-rate SDF streaming applications.</p> <p>Note</p> <p>The DSEL term can be sometimes confusing and <code>AFF3CT-core</code> can also be seen as a standard C++ library. The name \"DSEL\" comes from the ability  to write interpreted Turing-complete programs using the C++ library.</p> <p>Warning</p> <p>This library is NOT intended to address data and task parallelisms. <code>AFF3CT-core</code> focus on replication and pipeline parallelisms. For data  parallelism, <code>AFF3CT-core</code> combines well with OpenMP. If you look for task parallelism, using OpenMP can also be a possible solution, or other runtime  like the excellent StarPU can be a  good choice.</p>"},{"location":"#contents-of-the-documentation","title":"Contents of the Documentation","text":"<p>Basic components:</p> <ol> <li>Task</li> <li>Module</li> <li>Socket</li> <li>Sequence &amp; Subsequence</li> <li>Pipeline </li> <li>Control flow</li> </ol> <p>New features and discussions:</p> <ol> <li>Forward sockets</li> <li>Pipeline &amp; Control Flow</li> <li>Work in Progress</li> </ol>"},{"location":"module/","title":"Module","text":"<p>A module is a container of tasks. It contains the tasks  themselves and their inner data. Inner data can be useful to avoid useless  buffers re-allocations each time a task is executed, or a to contain a state  that is updated each time a task is triggered.  Multiple tasks can be grouped  into one module and can share data through the common module (as opposed to  the use of sockets). By definition,</p> <ul> <li>a stateless task is a task that does not have any inner data     (see <code>module::Stateless</code> class),</li> <li>a stateful task is a task that have inner data and, thus, a task that    need to be part of a module. </li> </ul> <p>Each time we need to create a statful task, we will create a new C++ class  that inherit from the <code>aff3ct::module::Module</code> class. The <code>Module</code> class  provides <code>protected</code> methods to create new tasks and <code>public</code> methods to  manipulate the module instances.</p>"},{"location":"module/#main-attributes","title":"Main Attributes","text":"<p><pre><code>std::vector&lt;std::shared_ptr&lt;runtime::Task&gt;&gt; tasks;\n</code></pre> The tasks list of the current module. All the tasks in the vector are  allocated (no <code>nullptr</code>).</p> <p><pre><code>std::vector&lt;std::shared_ptr&lt;runtime::Task&gt;&gt; tasks_with_nullptr;\n</code></pre> The tasks list of the current module where the tasks have a fixed position in the vector. This is useful when a task in conditionally created. In the case of a task is not created in the current module, its value is set to  <code>nullptr</code>.</p> <p><pre><code>size_t n_frames;\n</code></pre> Number of frames/streams to process each time a task is executed. For  instance, if <code>n_frames == 2</code>, all the tasks of the current module will  process 2 frames each time there are triggered.</p> <p><pre><code>std::string name;\n</code></pre> Name of the Module. This name is the same for all the instances of one class.</p> <p><pre><code>std::string short_name;\n</code></pre> Short name of the Module. This name is the same for all the instances of one  class.</p> <p><pre><code>std::string custom_name;\n</code></pre> Custom name of the Module. This name can be redefined by the user for each  instance.</p>"},{"location":"module/#main-protected-methods","title":"Main Protected Methods","text":"<p><pre><code>void set_name(const std::string &amp;name);\n</code></pre> Sets the module name.</p> <p><pre><code>void set_short_name(const std::string &amp;short_name);\n</code></pre> Sets the module short name.</p> <p><pre><code>runtime::Task&amp; create_task(const std::string &amp;name, const int id = -1);\n</code></pre> Creates a new task, two tasks cannot share the same <code>name</code>.</p> <p><pre><code>template &lt;typename T&gt;\nsize_t create_socket_in(runtime::Task&amp; task, const std::string &amp;name, const size_t n_elmts);\n</code></pre> Creates an input socket over a given task.</p> <p><pre><code>template &lt;typename T&gt;\nsize_t create_socket_out(runtime::Task&amp; task, const std::string &amp;name, const size_t n_elmts);\n</code></pre> Creates an output socket over a given task.</p> <p><pre><code>template &lt;typename T&gt;\nsize_t create_socket_fwd(runtime::Task&amp; task, const std::string &amp;name, const size_t n_elmts);\n</code></pre> Creates a forward socket over a given task.</p> <p><pre><code>void create_codelet(runtime::Task&amp; task, std::function&lt;int(module::Module &amp;m, runtime::Task &amp;t, onst size_t frame_id)&gt; codelet);\n</code></pre> Creates the codelet of the given task.</p>"},{"location":"module/#main-public-methods","title":"Main Public Methods","text":"<p><pre><code>size_t get_n_frames() const;\n</code></pre> Returns the number of frames to process in this Module.</p> <p><pre><code>void set_n_frames(const size_t n_frames);\n</code></pre> Sets the number of frames to process each time a task is executed.</p> <p><pre><code>const std::string&amp; get_name() const;\n</code></pre> Returns the module name.</p> <p><pre><code>const std::string&amp; get_short_name() const;\n</code></pre> Returns the module short name.</p> <p><pre><code>void set_custom_name(const std::string &amp;custom_name);\n</code></pre> Sets the module custom name (each instance can have a different custom name).</p> <p><pre><code>const std::string&amp; get_custom_name() const;\n</code></pre> Gets the custom name.</p> <p><pre><code>runtime::Socket&amp; operator[](const std::string &amp;tsk_sck);\n</code></pre> Returns the socket if it exists. The expected string format is  <code>\"task_name::socket_name\"</code>.</p> <p><pre><code>runtime::Task&amp; operator()(const std::string &amp;tsk_name);\n</code></pre> Returns the task if it exists. The input string has to match an existing task  name in this module.</p>"},{"location":"pipeline/","title":"Pipeline","text":"<p>A pipeline is a feature offered by <code>AFF3CT-core</code> allowing to split a sequence into multiple stages. Each stage is executed  on one or more threads in parallel. The pipeline takes care of the  synchronizations between stages. This is achieved through an implementation  of a producer/consumer algorithm.</p> <p> </p> Example a sequence on the left and a pipeline on the right. <p>A pipeline is a C++ object of the <code>aff3ct::runtime::Pipeline</code> class. The  following sections try to give an overview of the most important attributes and  methods to facilitate the code understanding.</p>"},{"location":"pipeline/#main-attributes","title":"Main Attributes","text":"<p><pre><code>runtime::Sequence original_sequence;\n</code></pre> The original sequence from which the pipeline was created.</p> <p> <pre><code>std::vector&lt;std::shared_ptr&lt;runtime::Sequence&gt;&gt; stages;\n</code></pre> Vector of the different stages in the pipeline. Each stage is a sequence.</p> <p><pre><code>std::vector&lt;std::pair&lt;std::tuple&lt;runtime::Socket*, size_t, size_t, size_t,size_t&gt;,\n            std::tuple&lt;runtime::Socket*, size_t, size_t, size_t&gt;&gt;&gt; sck_orphan_binds;\n</code></pre> Vector of sockets with broken connections due to the pipeline stages creation (hence \"orphan\"). These sockets will be bound later to special modules called adaptors to make \"bridges\" between the stages.</p> <p><pre><code>std::vector&lt;std::tuple&lt;runtime::Socket*, runtime::Socket*, size_t&gt;&gt; adaptors_binds;\n</code></pre> Vector of tuple (<code>input</code>, <code>output</code>, <code>priority</code>) of the created adaptors,  <code>priority</code> is used to order the tuples.</p>"},{"location":"pipeline/#main-methods","title":"Main Methods","text":"<p><pre><code>void exec();\n</code></pre> This is the public method that runs the pipeline in loop. Other variants exist where it is possible to give a stop condition function.</p> <pre><code>void init(const std::vector&lt;runtime::Task*&gt; &amp;firsts,\n          const std::vector&lt;runtime::Task*&gt; &amp;lasts,\n          const std::vector&lt;std::tuple&lt;std::vector&lt;runtime::Task*&gt;, std::vector&lt;runtime::Task*&gt;, std::vector&lt;runtime::Task*&gt;&gt;&gt; &amp;sep_stages = {},\n          const std::vector&lt;size_t&gt; &amp;n_threads = {},\n          const std::vector&lt;size_t&gt; &amp;synchro_buffer_sizes = {},\n          const std::vector&lt;bool&gt; &amp;synchro_active_waiting = {},\n          const std::vector&lt;bool&gt; &amp;thread_pinning = {},\n          const std::vector&lt;std::vector&lt;size_t&gt;&gt; &amp;puids = {});\n</code></pre> <p>This method creates the pipeline given:</p> <ul> <li>The first and last tasks of the original sequence (<code>firsts</code> and <code>lasts</code>).</li> <li>The first and last tasks of each stage (<code>sep_stages</code>).</li> <li>The number of threads to allocate to each stage (<code>n_threads</code>).</li> <li>The number of buffers between stages (<code>synchro_buffer_sizes</code>).</li> <li>The type of waiting for the adaptor tasks (<code>synchro_active_waiting</code>).</li> </ul> <p>Note</p> <p>AFF3CT doesn't support consecutive multi-threaded stages yet.</p> <p><pre><code>void create_adaptors(const std::vector&lt;size_t&gt; &amp;synchro_buffer_sizes = {},\n                     const std::vector&lt;bool&gt; &amp;synchro_active_waiting = {});\n</code></pre> This function creates the Adaptor modules (and so the <code>pull</code> &amp; <code>push</code> tasks)  that are added between each stage to transmit data from the stage \\(S\\) to the  stage \\(S+1\\). </p> <p><pre><code>void _bind_adaptors(const bool bind_adaptors = true);\n</code></pre> Adaptor module tasks <code>pull</code> &amp; <code>push</code> need to be bound to each task in the two consecutive stages, the target sockets to bind are stored in the vector <code>sck_orphan_binds.</code></p> <p></p>"},{"location":"pipeline/#adaptor","title":"Adaptor","text":"<p><code>aff3ct::module::Adaptor</code> is a special module automatically inserted between  stages when creating a pipeline and serve as \"bridges\" between them, they are  bound to first and last tasks of the consecutive stages. The purpose of adaptors  is to synchronize data exchange between each stage using pre-allocated buffer  pools. There are 4 tasks performed by adaptors:</p> <ul> <li><code>push_1</code>: when the \\(S\\) stage is executed on one thread and the \\((S+1)\\) stage    is executed on multiple threads. The function gets an empty buffer and fills    it with the data produced in the stage \\(S\\). The buffers are filled using a    round-robin algorithm.</li> <li><code>pull_n</code>: when the \\(S\\) stage is executed on multiple threads and the \\((S-1)\\)   stage is on one thread. It is the task executed just after the <code>push_1</code>, it   takes a filled buffer from the inter-stage pool and forwards the data. There    is a <code>pull_n</code> task for every thread of the stage.</li> <li><code>push_n</code>: when the \\(S\\) stage is executed on multiple threads and the \\((S+1)\\)   stage is on one thread. The task takes an empty buffer from the pool and fills   it with the data produced by the thread. There is a <code>push_n</code> task for each   thread of the stage.</li> <li><code>pull_1</code>: when the \\(S\\) stage is executed on one thread and the \\((S-1)\\) stage    is on multiple threads, it's the task executed just after the <code>push_n</code>. It    takes filled buffers from the pool using the same round-robin algorithm as    <code>push_1</code> and forward the data.</li> </ul>"},{"location":"pipeline/#main-attributes_1","title":"Main Attributes","text":"<p><pre><code>const size_t buffer_size;\n</code></pre> The inter-stage buffer pool size.</p> <p><pre><code>std::shared_ptr&lt;std::vector&lt;std::vector&lt;std::vector&lt;int8_t*&gt;&gt;&gt;&gt; buffer;\n</code></pre> Pointers to each buffer of the inter-stage pool.</p> <p><pre><code>std::shared_ptr&lt;std::vector&lt;std::atomic&lt;uint64_t&gt;&gt;&gt; first;\nstd::shared_ptr&lt;std::vector&lt;std::atomic&lt;uint64_t&gt;&gt;&gt; last;\n</code></pre> Two pointers used to monitor the buffer pool, <code>first</code> is used to get the filled buffers, and <code>last</code> for the empty ones.</p>"},{"location":"pipeline/#main-methods_1","title":"Main Methods","text":"<p>These are the methods used to synchronize the buffer pool between the pipeline stages. When getting a buffer, the thread may sleep if there is no empty  buffer available. When a new empty buffer will be available, the sleeping  thread will be woken up.</p> <p><pre><code>void* get_empty_buffer(const size_t sid);\n</code></pre> Get a pointer to the first empty buffer in the pool (at index <code>last</code>).</p> <p><pre><code>void* get_filled_buffer(const size_t sid);\n</code></pre> Get a pointer to the first filled buffer in the pool (at index <code>first</code>).</p> <p><pre><code>void* get_empty_buffer(const size_t sid, void* swap_buffer);\n</code></pre> Get a pointer to the first empty buffer in the pool, and replace this buffer with a new one pointed by <code>swap_buffer</code> parameter. </p> <p><pre><code>void* get_filled_buffer(const size_t sid, void* swap_buffer);\n</code></pre> Get a pointer to the first filled  buffer in the pool, and replace this buffer with a new one pointed by <code>swap_buffer</code> parameter.</p> <p><pre><code>void wake_up_pusher();\n</code></pre> The puller can wake up a push task if this one is waiting for an empty buffer.</p> <p><pre><code>void wake_up_puller();\n</code></pre> The pusher can wake up a pull task if this one is waiting for an empty buffer.</p>"},{"location":"pipeline_ctrl_flow/","title":"Pipeline &amp; Control Flow","text":""},{"location":"pipeline_ctrl_flow/#introduction","title":"Introduction","text":"<p><code>AFF3CT-core</code> allows the user to control the execution flow of sequences through the use of switcher, however sequences are often used within the context of pipelines and thus some slight behavior adjustments  were required for them to consistently work.</p>"},{"location":"pipeline_ctrl_flow/#technical-improvement","title":"Technical Improvement","text":""},{"location":"pipeline_ctrl_flow/#finding-the-last-sub-sequence","title":"Finding the Last Sub-sequence","text":"<p>Upon creation, a pipeline must add <code>pull</code> and <code>push</code> tasks at the beginning and  the end of the sequences making up its stages (see pipeline  section and sequence section for the relationship between the  two). For that purpose, a DFS algorithm is used to traverse the  directed graph starting from the root of the sequence,  marking every node on the path and returning the last node it passed through.  This however can return incorrect nodes depending on the configuration of the  sequence.</p> <p>Pseudo-code <pre><code>Node Last_Subseq(Node n):\n    mark(n)\n    Node last_node = n\n    for every child c of n that is not marked:\n        last_node = Last_Subseq(c)\n    return last_node\n</code></pre></p>"},{"location":"pipeline_ctrl_flow/#dfs-for-the-last-sub-sequence","title":"DFS for the Last Sub-sequence","text":"SwitchLoopNo switcher <p><pre><code>    graph LR;\n    A(SS 1)--&gt;B(SS commute);\n    B(SS commute)-.-&gt;C(SS Branch 1);\n    B(SS commute)-.-&gt;D(SS Branch 2);\n    B(SS commute)-.-&gt;E(SS Branch 3);\n    C(SS Branch 1)-.-&gt;F(SS select);\n    D(SS Branch 2)-.-&gt;F(SS select);\n    E(SS Branch 3)-.-&gt;F(SS select);\n    F(SS select)--&gt;G(SS 2);</code></pre> Here are the paths the DFS would take are</p> <ul> <li>[<code>SS 1</code>, <code>SS commute</code>, <code>SS Branch 1</code>, <code>SS select</code>, <code>SS 2</code>] : returns <code>SS 2</code></li> <li>[<code>SS 1</code>, <code>SS commute</code>, <code>SS Branch 2</code>] : returns <code>SS Branch 2</code></li> <li>[<code>SS 1</code>, <code>SS commute</code>, <code>SS Branch 3</code>] : returns <code>SS Branch 3</code></li> </ul> <p>As the function is recursive, it returns the result of the last path taken: <code>SS Branch 3</code>, which is incorrect, <code>SS 2</code> is the expected result.</p> <p><pre><code>graph LR;\nA(SS 1)-.-&gt;B(SS select);\nB(SS select)--&gt;C(SS 2);\nC(SS 2)--&gt;F(SS commute);\nF(SS commute)-.-&gt;E(SS 3);\nE(SS 3)-.-&gt;B(SS select);\nF(SS commute)-.-&gt;G(SS 4);</code></pre> Here are the paths the DFS would take are</p> <ul> <li>[<code>SS 1</code>, <code>SS select</code>, <code>SS 2</code>, <code>SS commute</code>, <code>SS 3</code>] : returns <code>SS 3</code></li> <li>[<code>SS 1</code>, <code>SS select</code>, <code>SS 2</code>, <code>SS commute</code>, <code>SS 4</code>] : returns <code>SS 4</code></li> </ul> <p>As the function is recursive, it returns the result of the last path taken: <code>SS 4</code>, which is correct, but deceptive. It only happened to work because of the order in which the children of node <code>SS commute</code> were parsed. If <code>SS 4</code> was parsed first then it would have returned <code>SS 3</code>, this kind of behavior is problematic as the algorithm should not depend on which children is first in a list as that is not relevant to the layout of the graph.</p> <p><pre><code>graph LR;\nA(SS 1);</code></pre> As explained in the sequence section, a sequence with no  switcher would only have a single sub-sequence, thus the DFS  would return <code>SS 1</code> as the last sub-sequence which is correct.</p>"},{"location":"pipeline_ctrl_flow/#improved-dfs","title":"Improved DFS","text":"<p>The solution is to consider the node without children as the last one. <pre><code>Node Last_Subseq(Node n):\n    mark(n)\n    if n is childless:\n        return n\n    else\n        Node last_node = null\n        for every child c of n that is not marked:\n            Node branch_result = Last_Subseq(c)\n            if branch_result != null:\n                last_node = branch_result\n        return last_node\n</code></pre></p> <p>This is simple and efficient.</p> <p>Info</p> <p>This is the current implementation in <code>AFF3CT-core</code>.</p>"},{"location":"pipeline_ctrl_flow/#finding-invalid-switchers","title":"Finding Invalid Switchers","text":"<p>Another use of the DFS algorithm is to notify the user of improper uses of  switchers. <code>commute</code> and <code>select</code> tasks must always have paths linking each  other. We find broken paths by traversing the sub-sequences with a modified DFS.  Since the DFS already records parsed nodes we can use this information to tell  if a <code>commute</code> or <code>select</code> task is orphan (and thus, invalid).</p>"},{"location":"pipeline_ctrl_flow/#depth-first-search-for-invalid-switchers","title":"Depth-first Search for Invalid Switchers","text":"<p>The following sub-sequences denotes an invalid binding.</p> <pre><code>    graph LR;\n    A(SS 1)--&gt;B(SS commute);\n    B(SS commute)-.-&gt;C(SS Branch 1);\n    B(SS commute)-.-&gt;D(SS Branch 2);\n    B(SS commute)-.-&gt;E(SS Branch 3);\n    C(SS Branch 1)-.-&gt;F(SS select);\n    D(SS Branch 2)-.-&gt;F(SS select);\n    F(SS select)--&gt;G(SS 2);</code></pre> <p>This sub-sequence is invalid because the last <code>SS Branch 3</code> has no path to the  <code>select</code> task. Here are the paths the DFS would take:</p> <ul> <li>[<code>SS 1</code>, <code>SS commute</code>, <code>SS Branch 1</code>, <code>SS select</code>, <code>SS 2</code>] : No problem, the    list contains both commute and select</li> <li>[<code>SS 1</code>, <code>SS commute</code>, <code>SS Branch 2</code>, <code>SS select</code>, <code>SS 2</code>] : Ditto</li> <li>[<code>SS 1</code>, <code>SS commute</code>, <code>SS Branch 3</code>] : Invalid, this path only contains a    <code>commute</code>. We notify the user regarding the broken <code>commute</code>.</li> </ul> <pre><code># Note that path_taken here is copied between recursive calls and NOT shared\nvoid Check_ctrl_flw(Node n, List path_taken):\n    if n is not in path_taken and n is not childless\n        path_taken.append(n)\n        for every child c of n:\n            Check_ctrl_flw(c, path_taken)\n    else\n        for i = 0, i &lt; path_taken.size, i++:\n            if path_taken[i] does not contain a switcher task:\n                continue:\n            Task first_task  = path_taken[i] #We found the first task\n            for j = i, j &lt; path_taken.size, j++:\n                # We found the second task\n                if path_taken[j] is the opposite switcher task of path_taken[i]: \n                    break:\n            # We went through the entire path and didn't find the other switcher \n            # task\n            if j == path_taken.size \n                throw an error\n</code></pre>"},{"location":"pipeline_ctrl_flow/#tests","title":"Tests","text":"<p>Some specific tests have been added to the project to validate the robustness of  the control flow inside a pipelie stage.</p> Switch-case inside a parallel stageNested loops inside a parallel stage <p> <code>test-exclusive-paths-pipeline</code>. <pre><code>test-exclusive-paths-pipeline -t 4 -i ../CMakeLists.txt\n</code></pre> In this test, the read bytes (from the source \\(t_1\\)) are alternatively  converted to upper case and to lower case (see \\(t_5\\) and \\(t_6\\) task). As  explained in the Work in Progress section, we  need to add a <code>relay</code> task (\\(t_8\\)) after the <code>select</code> task (\\(t_7\\)) to make it work.</p> <p> <code>test-nested-loops-pipeline</code>. <pre><code>test-nested-loops-pipeline -i 20 -j 50 -t 8\n</code></pre> In this test, two nested loops inside a parallel stage are tested. <code>-i</code> sets the number of iterations in the outer loop (\\(t_4\\) Iterator) and  <code>-j</code> sets the number of iterations in the inner loop (\\(t_7\\) Iterator). As explained in the Work in Progress section, we  need to add <code>relay</code> tasks (\\(t_2\\) and \\(t_{15}\\)) before the first <code>select</code>  task (\\(t_3\\)) and after the last <code>commute</code> task (\\(t_5\\)) to make it work.</p>"},{"location":"sequence/","title":"Sequence","text":""},{"location":"sequence/#sequence","title":"Sequence","text":"<p>A sequence is a set of bound tasks. A sequence represents the  graph to execute for each new frame (= new stream). When a sequence is built,  the tasks execution order is fixed. For each frame, the tasks will be executed  in the same order.</p> <p> </p> Example a simple sequence of tasks (single threaded). <p>A sequence is a C++ object of the <code>aff3ct::runtime::Sequence</code> class. The  following sections try to give an overview of the most important attributes and  methods to facilitate the code understanding.</p>"},{"location":"sequence/#main-attributes","title":"Main Attributes","text":"<p><pre><code>size_t n_threads;\n</code></pre> The number of threads that are executing the sequence.</p> <p><pre><code>std::vector&lt;tools::Digraph_node&lt;runtime::Sub_sequence&gt;*&gt; sequences;\n</code></pre> Vector of sub-sequences of the main sequence (one per thread).</p> <p><pre><code>std::vector&lt;size_t&gt;                      firsts_tasks_id;\nstd::vector&lt;size_t&gt;                      lasts_tasks_id;\nstd::vector&lt;std::vector&lt;runtime::Task*&gt;&gt; firsts_tasks;\nstd::vector&lt;std::vector&lt;runtime::Task*&gt;&gt; lasts_tasks;\n</code></pre> Vectors used to get the firsts and lasts tasks of the sequence. The first tasks are the ones without parents, and  the last are the ones without children in the constructed directed graph.</p> <p><pre><code>std::vector&lt;std::vector&lt;module::Module*&gt;&gt; all_modules;\n</code></pre> Vector of modules contained within the sequence.</p>"},{"location":"sequence/#main-methods","title":"Main Methods","text":"<p><pre><code>void exec();\n</code></pre> This is the public method that runs the sequence in loop. Other variants exist where it is possible to give a stop condition function.</p> <p><pre><code>void gen_processes(const bool no_copy_mode = false);\n</code></pre> This function is one of the most important of the sequence class, it is called by the <code>Sequence</code> constructor. Its main purpose is to parse the sub-sequence  graph and to perform some operations that can modify the user bindings.  Additionally, some tasks can be optimized and/or interpreted as a DSEL keyword. </p> <p>Warning</p> <p>Before reading the following paragraphs you should be familiar with the  Adaptor and Switcher modules.</p> <p>Here is a list of the transformations that are performed during the  <code>gen_processes</code> method:</p> <ul> <li><code>push</code> &amp; <code>pull</code> tasks (from <code>Adaptor</code> module): as explained in the     adaptor's section, tasks change their <code>dataptr</code> when     they get the new buffers from the inter-stage pool, the new pointer needs to     be updated for each socket bound to the old one. This behavior is added     through a <code>process</code> (noting to do with OS processes) that encapsulates <code>push</code>     and <code>pull</code> tasks. This <code>process</code> is triggered each time there is a <code>pull</code> or    <code>push</code> task execution in the sequence.</li> <li><code>commute</code> &amp; <code>select</code> tasks (from <code>Switcher</code> module): this two tasks are used     to select which path to flow for the execution, when a path is selected the     bound sockets needs to update their <code>dataptr</code> to follow the right one. Same     as before, a dedicated <code>process</code> is created and triggered.</li> <li>Other tasks: a dumb <code>process</code> will be created for each task and it will only     call its corresponding task.</li> </ul> <p><pre><code>void explore_thread_rec(Socket* socket, std::vector&lt;runtime::Socket*&gt;&amp; list_fwd);\n</code></pre> The function is called by <code>gen_processes</code> to get all the bound sockets (next) of the modified one, if the encountered socket is of type <code>forward</code> the function is called recursively on this new socket (see the Forward socket and pipeline section). This call is performed  once at sequence build.</p> <p><pre><code>void explore_thread_rec_reverse(runtime::Socket* socket, std::vector&lt;runtime::Socket*&gt;&amp; list_fwd);\n</code></pre> The function does the same thing as the previous one, but in the other sense (previous).</p> <p></p>"},{"location":"sequence/#sub-sequence","title":"Sub-sequence","text":"<p>When control flow tasks are introduced into a sequence, the execution is not only defined by the tasks binding but also by their output  sockets. For this purpose, tasks are grouped into sub-sequences. Sub-sequences  are organized in a directed graph with 2 nodes designated as begin  and end, respectively. This graph is recursively built during a sequence  initialization from the first task and going from bound <code>output</code>/<code>forward</code>  socket to bound <code>input</code>/<code>forward</code> socket. When a control flow task (<code>select</code> or  <code>commute</code>) is reached, a new control flow node is created and new children nodes  for each of its paths. Only a single of those paths can be taken during  execution hence why they are referred to as exclusive paths. This also  means that a sequence with no control flow task will always have a single  sub-sequence, because it has a single path.</p> <p>Upon execution the sequence will iterate over its sub-sequences and execute  every task they contain, if one of those tasks happens to be a <code>commute</code> it will select the children node designated by its path attribute thus branching in the execution.</p> <p><code>aff3ct::runtime::Sub_sequence</code> (not to be confused with  <code>aff3ct::module::Subsequence</code>!) main attributes are described in the following section.</p>"},{"location":"sequence/#main-attributes_1","title":"Main Attributes","text":"<p><pre><code>runtime::subseq_t type;\n</code></pre> The sub-sequence types can be: <code>STD</code>, <code>COMMUTE</code> and <code>SELECT</code>. This type is used  by the <code>_exec()</code> method to determine which exclusive path to take during  execution.</p> <p><pre><code>std::vector&lt;std::function&lt;const int*()&gt;&gt; processes;\n</code></pre> Whenever <code>_exec()</code> reaches a new sub-sequence it executes every function contained in this list, there is one for each task in the sub-sequence. Refer to <code>gen_processes()</code> to understand how they are created and what they contain.</p> <p><pre><code>std::vector&lt;size_t&gt; tasks_id;\n</code></pre> The ids of the tasks the <code>processes</code> were generated from, <code>tasks_id[0]</code> is the id of task <code>processes[0]</code> was made with.</p> <p><pre><code>size_t id;\n</code></pre> The sub-sequence's id. <pre><code>std::vector&lt;std::vector&lt;std::vector&lt;runtime::Socket*&gt;&gt;&gt; rebind_sockets;\nstd::vector&lt;std::vector&lt;std::vector&lt;void*&gt;&gt;&gt; rebind_dataptrs;\n</code></pre> This two vectors are used within the <code>gen_process()</code> method to save the sockets and their <code>dataptr</code> to update during the runtime rebinding.</p> <p></p>"},{"location":"sequence/#digraph-node","title":"Digraph Node","text":"<p>Sub-sequences make up a directed graph. Whenever a sub-sequence  is accessed it is through this class (<code>aff3ct::tools::Digraph_node</code>) as  sub-sequences themselves do not contain information regarding the graph.</p>"},{"location":"sequence/#main-attributes_2","title":"Main Attributes","text":"<p><pre><code>std::vector&lt;tools::Digraph_node&lt;T&gt;*&gt; fathers;\nstd::vector&lt;tools::Digraph_node&lt;T&gt;*&gt; children;\n</code></pre> The nodes pointing to this node and the ones it points to respectively.</p> <p><pre><code>T* contents; /*!&lt; Pointer to the node contents, could be anything. */\n</code></pre> The contents of the node, usually a sub-sequence.</p>"},{"location":"socket/","title":"Socket","text":"<p>Sockets are used to exchange data between tasks. There are 3  different types of sockets:</p> <ul> <li>Input socket (<code>socket_t::SIN</code>),</li> <li>Output socket (<code>socket_t::SOUT</code>),</li> <li>Forward socket (<code>socket_t::SFWD</code>): read and write data (see the forward    socket section).</li> </ul> <p>A task can have multiple sockets of different types (input, output and forward). This is illustrated in the following figure:</p> <p> </p> Tasks with different socket types. <p>A socket is a C++ object of the <code>aff3ct::runtime::Socket</code> class. The following sections try to give an overview of the most important attributes and methods to facilitate the code understanding.</p>"},{"location":"socket/#main-attributes","title":"Main Attributes","text":"<p><pre><code>socket_t type;\n</code></pre> Define the socket type <code>IN</code>, <code>OUT</code> or <code>FWD</code>.</p> <p><pre><code>std::string name;\n</code></pre> Custom name for the socket.</p> <p><pre><code>std::type_index datatype;\n</code></pre> The type of data exchanged.</p> <p><pre><code>void* dataptr;\n</code></pre> Pointer to the data of the socket (memory space).</p> <p><pre><code>std::vector&lt;Socket*&gt; bound_sockets;\n</code></pre> The <code>input</code> or <code>forward</code> sockets bound to the current socket. Only relevant  for <code>output</code> or <code>forward</code> sockets.</p> <p><pre><code>Socket* bound_socket;\n</code></pre> The unique <code>output</code> or <code>forward</code> socket bound to the current socket. Only relevant for <code>input</code> or <code>forward</code> sockets.</p>"},{"location":"socket/#main-methods","title":"Main Methods","text":"<p>The most important methods of the socket class are <code>bind</code> and <code>unbind</code>.</p> <p><pre><code>void bind(Socket &amp;s_out, const int priority = -1);\n</code></pre> This function is used to connect sockets with each other, it can be called by an <code>input</code> or <code>forward</code> socket and takes as parameter an output or forward socket. The function gets the caller's <code>dataptr</code> and redirects it to <code>s_out dataptr</code>.</p> <p>Below some examples of valid and invalids socket bindings :</p> Valid bindingsInvalid bindings <p> Examples of valid socket bindings. </p> <p> Examples of invalid socket bindings. </p> <p>For invalid socket bindings, <code>AFF3CT-core</code> will throw an exception at runtime.</p> <p><pre><code>void unbind(Socket &amp;s_out, const int priority = -1);\n</code></pre> This function is used to disconnect sockets from each other. </p> <p>Note</p> <p><code>s_out</code> must be bound to the caller socket otherwise <code>AFF3CT-core</code> will throw an exception.</p>"},{"location":"socket/#standard-sinsout-sockets-versus-sfwd-socket","title":"Standard <code>SIN</code>/<code>SOUT</code> Sockets versus <code>SFWD</code> Socket","text":"<p>Using a couple of <code>SIN</code>/<code>SOUT</code> sockets or a single <code>SFWD</code> socket can have an  impact on the code behavior and on the performance of the application. The most  important point is the impact on the socket <code>dataptr</code> attribute.</p> <ul> <li>In the case of <code>SIN</code>/<code>SOUT</code> sockets, the input and the output sockets have    their own <code>dataptr</code>. The <code>input</code> socket receives the pointer from its bound    socket and the <code>output</code> socket has its own allocated memory space, the data    received and computed by the task are written to the <code>output</code> memory space.    The initial data are not modified in this case, there are no side effects.</li> <li>In the case of a single <code>SFWD</code> socket, the socket receives its <code>dataptr</code> from    the bound socket like an <code>input</code>. But unlike in the <code>SIN</code>/<code>SOUT</code> case, the    computed data are written directly on the provided memory space, thus    overwriting it (and potentially losing important information), there are    side effects.</li> </ul>"},{"location":"socket_fwd/","title":"Forward Socket","text":""},{"location":"socket_fwd/#introduction","title":"Introduction","text":"<p>The forward socket is a new feature added to <code>AFF3CT-core</code> to improve the performance and the flexibility in some applications. As mentioned in the  Socket section, the <code>SFWD</code> works as an input and output at the same  time. It receives its <code>dataptr</code> from the input bound socket and this same  pointer is sent to all the output bound sockets, which means that all the  consecutive tasks bound by <code>SFWD</code> share the same memory space.</p> <pre><code>graph LR;\nA(FWD)--&gt;B(FWD); A(FWD)-.-&gt;K{MEM};\nB(FWD)--&gt;C(FWD); B(FWD)-.-&gt;K{MEM};\nC(FWD)--&gt;F(FWD); C(FWD)-.-&gt;K{MEM};\nF(FWD)-.-&gt;K{MEM};</code></pre>"},{"location":"socket_fwd/#technical-improvement","title":"Technical Improvement","text":"<p>The implementation of the forward socket for sequences was mainly  straightforward because it behaves the same way as the input and output sockets.  We just had to distinguish when it is used as an input and when it is used as an  output. However, the most challenging part was to combine forward socket with  the pipeline. Especially when forward sockets are bound from  one stage to an other.</p>"},{"location":"socket_fwd/#forward-sockets-and-pipelines","title":"Forward Sockets and Pipelines","text":"<p>As explained in the adaptor's section, a pool of buffers  is used between each stage of the pipeline. The adaptor gets a buffer from  this pool and uses it to update the output socket of its <code>pull</code> task  (<code>dataptr</code> attribute). This output socket is then bound to the input socket of  the next tasks. In other words, all the input sockets connected to the <code>pull</code>  output socket need to be updated with the new <code>dataptr</code> address.</p> <p>The forward sockets are all pointing to the same <code>dataptr</code>, so getting a new  buffer means that we have to update the <code>dataptr</code> of all the consecutive bound  forward sockets to this new memory space. The same update need to be done in the reversed way when the <code>dataptr</code> is exchanged at the end of the stage. For that,  we added two recursive methods as explained in the sequence  section (see <code>explore_thread_rec()</code> and <code>explore_thread_rec_reverse()</code>).</p>"},{"location":"socket_fwd/#tests","title":"Tests","text":"<p>Some specific tests have been added to the project to validate the robustness of  the forward socket implementation.</p>"},{"location":"socket_fwd/#specific-for-forward-socket","title":"Specific for Forward Socket","text":"Pipeline with two different chainsPipeline with distant stage bindingPipeline with distant stage binding and mix of SIN, SOUT &amp; SFWD <p> <code>test-simple-pipeline-double-chain</code>. <pre><code>test-simple-pipeline-double-chain -t 3\n</code></pre> The purpose of this graph is to test the buffer exchange with <code>SIO</code> and <code>SFWD</code>, both on the same stage.</p> <p> <code>test-complex-pipeline-full-fwd</code>. <pre><code>test-complex-pipeline-full-fwd -t 3\n</code></pre> The purpose of this graph is to test a <code>SFWD</code> bound to two <code>SFWD</code> in two different stages, and how the buffer exchange behave with connections between distant stages \\(S1\\) and \\(S4\\).  </p> <p> <code>test-complex-pipeline-inter-stage</code>. <pre><code>test-complex-pipeline-inter-stage -t 3\n</code></pre> This test is a combination of the two previous tests, we have a <code>SOUT</code> bound to a <code>SIN</code> in stage \\(S2\\) and a <code>SFWD</code> in stage \\(S4\\).</p>"},{"location":"socket_fwd/#generic-pipeline","title":"Generic Pipeline","text":"<p>A new test with a generic pipeline has also been added. It is possible to define  the middle tasks from the command line (the initial <code>Init</code> and last task <code>Sink</code>  are automatically added) using these parameters:</p> <ul> <li><code>-n</code>: the number of tasks on each stage.</li> <li><code>-t</code>: the number of threads on each stage.</li> <li>The socket type (<code>SIO</code> or <code>SFWD</code>) of the tasks:<ul> <li><code>-r</code>: specifying each socket type (<code>SIO</code> \\(\\rightarrow\\) <code>relay</code> task and          <code>SFWD</code> \\(\\rightarrow\\) <code>relayf</code> task).</li> <li><code>-R</code>: specifying socket type by stage (all the sockets of the stage will   be of this type).</li> </ul> </li> </ul> <p>Note</p> <p>You cannot use <code>-r</code> and <code>-R</code> parameters at the same time, they are  exclusive.</p> <p>Here are some examples of generated pipelines:</p> Simple pipelineSimple pipeline forwardSimple pipeline hybridSimple pipeline hybrid with a 5-stage pipeline <p> <code>test-generic-pipeline</code>: input/output sockets &amp; 3-stage pipeline. <pre><code>test-generic-pipeline -n \"(3)\" -t \"(3)\" -R \"(SIO)\"\n</code></pre></p> <p> <code>test-generic-pipeline</code>: forward sockets &amp; 3-stage pipeline. <pre><code>test-generic-pipeline -n \"(3)\" -t \"(3)\" -R \"(SFWD)\"\n</code></pre></p> <p> <code>test-generic-pipeline</code>: hybrid in/out and forward sockets &amp; 3-stage pipeline. <pre><code>test-generic-pipeline -n \"(3)\" -t \"(3)\" -r \"((SFWD,SIO,SFWD))\"\n</code></pre></p> <p> <code>test-generic-pipeline</code>: hybrid in/out and forward sockets &amp; 5-stage pipeline. <pre><code>test-generic-pipeline -n \"(4,1,2)\" -t \"(3,1,2)\" -r \"((SFWD,SIO,SFWD,SIO),(SFWD),(SIO,SIO))\"\n</code></pre></p>"},{"location":"switcher/","title":"Switcher","text":"<p>A switcher is a control flow module used to break sequences  into exclusive paths through its two tasks: <code>select</code> and  <code>commute</code>.  </p> <p>A switcher is a C++ object of the <code>aff3ct::module::Switcher</code> class. The  following sections try to give an overview of the most important attributes and  methods to facilitate the code understanding.</p>"},{"location":"switcher/#main-attributes","title":"Main Attributes","text":"<p> <pre><code>size_t path;\n</code></pre> The exclusive path to take when the <code>commute</code> task is reached. Read on the <code>ctrl socket</code> of <code>commute</code> task each time it is executed. The  initial <code>path</code> value is set to <code>n_data_sockets - 1</code> prior to the first  execution.</p> <p><pre><code>const size_t n_data_sockets;\n</code></pre> The number of data sockets for the <code>commute</code> and <code>select</code> tasks (not the total,  but the individual number).</p> <p><pre><code>const std::type_index datatype_commute;\nconst std::type_index datatype_select;\n</code></pre> The type of data conveyed by the data sockets of each task.</p> <p><pre><code>const size_t n_elmts_commute;\nconst size_t n_elmts_select;\n</code></pre> The number of elements conveyed by each data sockets. With <code>datatype</code> they define what and how much each data socket is expected to read/write.</p> <p><pre><code>const size_t n_bytes_commute;\nconst size_t n_bytes_select;\n</code></pre> The product of the size  of <code>datatype</code> with <code>n_elemts</code> for the total number of bytes expected on each data socket.</p>"},{"location":"switcher/#tasks","title":"Tasks","text":"<p>Since those tasks have a variable number of sockets they are accessed through the subcript <code>operator[]</code> with a numerical index or a <code>std::string</code> unlike  regular tasks which use namespaces and enumators.</p> <p>Examples:</p> Numerical indexes<code>std::string</code> <pre><code>Switcher swi(2, 6, typeid(uint8_t)); // n_data_sockets, n_elemts, datatype\n\nswi[module::swi::tsk::select ][0]; // input  socket data0\nswi[module::swi::tsk::select ][1]; // input  socket data1\nswi[module::swi::tsk::select ][2]; // output socket data\nswi[module::swi::tsk::select ][3]; // output socket status\n\nswi[module::swi::tsk::commute][0]; // input  socket data\nswi[module::swi::tsk::commute][1]; // input  socket ctrl\nswi[module::swi::tsk::commute][2]; // output socket data0\nswi[module::swi::tsk::commute][3]; // output socket data1\nswi[module::swi::tsk::commute][4]; // output socket status\n</code></pre> <pre><code>Switcher swi(2, 6, typeid(uint8_t)); // n_data_sockets, n_elemts, datatype\n\nswi[ \"select::in_data0\" ];         // input  socket data0\nswi[ \"select::in_data1\" ];         // input  socket data1\nswi[ \"select::out_data\" ];         // output socket data\nswi[ \"select::status\"   ];         // output socket status \n\nswi[\"commute::in_data\"  ];         // input  socket data\nswi[\"commute::in_ctrl\"  ];         // input  socket ctrl\nswi[\"commute::out_data0\"];         // output socket data0\nswi[\"commute::out_data1\"];         // output socket data1\nswi[\"commute::status\"   ];         // output socket status\n</code></pre> <p></p>"},{"location":"switcher/#commute","title":"Commute","text":"<p>The <code>commute</code> task is used to create exclusive paths. When the <code>commute</code>  task is executed it reads the <code>path</code> to take from its <code>ctrl</code> socket and  then copies the bytes from its <code>data</code> input socket to the <code>data{path}</code> output  socket. Then it sets the path attribute of the module to the one read.</p> <p>Any task bound to its output sockets before <code>status</code> will be considered in a diffferent exclusive path.</p> <p>Sockets</p> Type Name Index <code>Input</code> data 0 <code>Input</code> ctrl 1 <code>Output</code> data{0..N-1} {2..N+1} <code>Output</code> status N+2 <p></p>"},{"location":"switcher/#select","title":"Select","text":"<p>The <code>select</code> task is ued to join exclusive paths.</p> <p>When a <code>select</code> task is executed it gets the <code>path</code> from the module and copies the bytes from its <code>data{path}</code> input to its <code>data</code> output socket. Any  task bound to its input sockets will be considered in a different exclusive path.</p> <p>Danger</p> <p>Note that the execution will fail if the <code>path</code> it was executed from does not match the one in the module. That is most likely to happen in  a loop because the <code>select</code> is executed before the <code>commute</code>.  Then the path defaults to <code>n_data_sockets - 1</code> meaning that in a loop, the  first path taken before the first <code>select</code> execution should always be bound  to the last input socket.</p> <p>Sockets</p> Type Name Index <code>Input</code> data{0..N-1} {0..N-1} <code>output</code> data N <code>Output</code> status N+1 <p>"},{"location":"switcher/#examples","title":"Examples","text":"While loopSwitch-case <p> Example of a sequence with a while-loop. </p> <p> Example of a sequence with a switch-case. </p>"},{"location":"task/","title":"Task","text":"<p>A task represents the code executed by a node in the data flow graph. In  other languages, a task can be refereed as a job or a filter.  A task is defined by its input and output data and the code to execute when  triggered. In other word, a task comes with a set of data called  sockets (not to be confused with network and system sockets). The  sockets model the data that are consumed (input socket) and produced (output  socket) by the current task. Finally, the code to execute is stored in a  so-called codelet.</p> <p>A task is a C++ object of the <code>aff3ct::runtime::Task</code> class. The following sections try to give an overview of the most important attributes and methods to facilitate the code understanding.</p>"},{"location":"task/#main-attributes","title":"Main Attributes","text":"<p><pre><code>std::vector&lt;std::shared_ptr&lt;runtime::Socket&gt;&gt; sockets;\n</code></pre> The list of sockets that are attached to this task.</p> <p><pre><code>std::vector&lt;runtime::socket_t&gt; socket_type;\n</code></pre> The socket types corresponding to the previous <code>sockets</code> attribute, in the  same order. Can be <code>socket_t::SIN</code>, <code>socket_t::SOUT</code> or <code>socket_t::SFWD</code> for  input socket, output socket and forward socket, respectively.</p> <p><pre><code>std::vector&lt;std::vector&lt;uint8_t&gt;&gt; out_buffers;\n</code></pre> The allocated data of the output sockets of this task. If the <code>autoalloc</code>  attribute is set to <code>True</code> (see below) then the data are allocated here,  otherwise this vector is left empty.</p> <p><pre><code>std::function&lt;int(module::Module &amp;m, runtime::Task&amp; t, const size_t frame_id)&gt; codelet;\n</code></pre> The function called by <code>_exec()</code> method (see below), thus dictating the  task's behavior. Usually set in the module's constructor, should return a  <code>status_t</code>.</p> <p><pre><code>std::shared_ptr&lt;runtime::Socket&gt; fake_input_sockets;\n</code></pre> Fake input sockets are used when specifying dependencies between tasks directly. Thus, in intern, these dependencies are managed through \"fake input sockets\" that are created on-the-fly over the current task. The data of these sockets are ignored during the codelet execution.</p> <p><pre><code>bool autoalloc;\n</code></pre> If set to <code>True</code>, let <code>AFF3CT-core</code> allocate and reallocate memory needed by  the task. Data are only allocated in the output sockets. By default this  attribute is set to <code>True</code>.</p> <p><pre><code>bool stats;\n</code></pre> If true, records statistics regarding the task's execution, such as the  <code>duration</code>. By default this attribute is set to <code>False</code>.</p> <p><pre><code>bool fast;\n</code></pre> If true, skips <code>can_exec()</code> runtime check, thus, improving performance.  Sockets bound to this task will also be set to <code>fast</code>. By default this  attribute is set to <code>False</code>.</p> <p><pre><code>bool debug;\n</code></pre> If set to true, displays the task's sockets data and its status upon  execution (on the standard output). By default this attribute is set to  <code>False</code>.</p> <p><pre><code>module::Module *module;\n</code></pre> A pointer to the corresponding Module. See bellow for more information about what is precisely a Module.</p> <p><pre><code>const std::string name;\n</code></pre> A name to identify the task in the Module. This name is unique in the Module.</p>"},{"location":"task/#main-methods","title":"Main Methods","text":"<p><pre><code>const std::vector&lt;int&gt;&amp; exec(const int frame_id = -1, const bool managed_memory = true);\n</code></pre> Calls <code>_exec()</code> method, records execution statistics (if <code>stats == True</code>) and  prints the debug logs (if <code>debug == True</code>).</p> <p><pre><code>void _exec(const int frame_id = -1, const bool managed_memory = true);\n</code></pre> Executes the task's <code>codelet</code> and sets the <code>status</code> for this specific call. Called by <code>exec()</code> (see the above method).</p> <p><pre><code>bool can_exec() const;\n</code></pre> Returns <code>True</code> if all the sockets are associated to an allocated buffer,  otherwise returns <code>False</code>. Called by <code>exec()</code> method if <code>fast</code> is set to  <code>True</code>, skipped otherwise.</p> <p><pre><code>void bind(runtime::Task &amp;t_out, const int priority = -1);\n</code></pre> Add a fake input socket to the current task (see above <code>fake_input_sockets</code>  attribute) and binds it to the output <code>status</code> socket of the <code>t_out</code> task in  parameter. The new socket's <code>datatype</code> and <code>databytes</code> matches the output  <code>status</code> socket of <code>t_out</code>. <code>fake_input_sockets</code> is always <code>fast</code>. This  method has to be manually called by the user.</p> <p><pre><code>size_t unbind(runtime::Task &amp;t_out);\n</code></pre> Unbinds and deletes the corresponding input socket in the  <code>fake_input_sockets</code> attribute. Can be called by <code>Sequence::set_n_frames()</code>  or manually by the user.</p> <p><pre><code>void reset();\n</code></pre> Resets the task's statistics. Not to be confused with <code>Module::reset()</code>. Manually called by the user.</p>"},{"location":"wip/","title":"Work in Progress","text":""},{"location":"wip/#forward-socket-with-control-flow","title":"Forward Socket with Control Flow","text":"<p>Currently when <code>gen_processes()</code> is called, <code>select</code> and <code>commute</code> tasks do not  behave properly with <code>SFWD</code> tasks bound directly on their data sockets, indeed  they only rebind the first bound sockets while they should use  <code>explore_thread_rec()</code> to update the data pointers of every linked <code>SFWD</code>. For  now, tasks bound to switchers should be <code>SIO</code>.</p>"},{"location":"wip/#id-updates","title":"Id Updates","text":"<p>When <code>push</code> and <code>pull</code> tasks are inserted into the pipeline the  <code>update_tasks_id()</code> method is called to assert that the task IDs are still  coherent, the task with the greatest ID is used to insert the <code>push</code> task in  stages for instance. It uses the following algorithm.</p> <pre><code># It is called with min_id = 0 in the pipeline code, min_id is shared between \n# recursive calls and NOT copied because it is a reference\nvoid update_tasks_id(Node n, min_id):\n    mark(n)\n    for every task t in n:\n        t.set_id(min_id)\n        min_id += 1\n    for every child c of n that is not marked:\n        update_tasks_id(c, min_id)\n</code></pre> <p>This however can lead to issues. For instance when updating the IDs of a sequence with a switch-case.</p> <p>Warning</p> <p>The following is a graph of tasks, and NOT a graph of sub-sequences.</p> <pre><code>    graph LR;\n    A[Task_first ID : 0]--&gt;B[Task Commute ID : 1];\n    B[Task Commute ID : 1]-.-&gt;C[Task_b1 ID : 2];\n    B[Task Commute ID : 1]-.-&gt;D[Task_b2 ID : 3];\n    B[Task Commute ID : 1]-.-&gt;E[Task_b3 ID : 4];\n    C[Task_b1 ID : 2]-.-&gt;F[Task select ID : 5];\n    D[Task_b2 ID : 3]-.-&gt;F[Task select ID : 5];\n    E[Task_b3 ID : 4]-.-&gt;F[Task select ID : 5];\n    F[Task select ID : 5]--&gt;G[Task_last ID : 6];</code></pre> <p>Here is the result of the DFS-id update.</p> <pre><code>    graph LR;\n    A[Task_first ID : 0]--&gt;B[Task Commute ID : 1];\n    B[Task Commute ID : 1]-.-&gt;C[Task_b1 ID : 2];\n    B[Task Commute ID : 1]-.-&gt;D[Task_b2 ID : 5];\n    B[Task Commute ID : 1]-.-&gt;E[Task_b3 ID : 6];\n    C[Task_b1 ID : 2]-.-&gt;F[Task select ID : 3];\n    D[Task_b2 ID : 5]-.-&gt;F[Task select ID : 3];\n    E[Task_b3 ID : 6]-.-&gt;F[Task select ID : 3];\n    F[Task select ID : 3]--&gt;G[Task_last ID : 4];</code></pre> <p>This is not a coherent set of IDs, <code>Task_last</code> should not have an ID inferior than <code>Task_b2</code> and <code>Task_b3</code>, but due to the nature of the DFS algorithm it was assigned a lesser id because it was reached first, thus <code>Task_b2</code> was updated later and given a greater id.</p> <p>The current implementation uses the following algorithm.</p> <pre><code># We no longer have a minimum, instead we simply increment each ID by 1\nvoid update_tasks_id(Node n):\n    mark(n)\n    for every task t in n:\n        t.set_id(t.id + 1)\n    for every child c of n that is not marked:\n        update_tasks_id(c)\n</code></pre> <p>Which results in</p> <pre><code>    graph LR;\n    A[Task_first ID : 1]--&gt;B[Task Commute ID : 2];\n    B[Task Commute ID : 2]-.-&gt;C[Task_b1 ID : 3];\n    B[Task Commute ID : 2]-.-&gt;D[Task_b2 ID : 4];\n    B[Task Commute ID : 2]-.-&gt;E[Task_b3 ID : 5];\n    C[Task_b1 ID : 3]-.-&gt;F[Task select ID : 6];\n    D[Task_b2 ID : 4]-.-&gt;F[Task select ID : 6];\n    E[Task_b3 ID : 5]-.-&gt;F[Task select ID : 6];\n    F[Task select ID : 6]--&gt;G[Task_last ID : 7];</code></pre> <p>While this is a coherent set of IDs, we lost control over the <code>min_id</code>, which is less-than-ideal and thus every task has a new ID while they didn't need change. A better long term solution would perhaps be to use the <code>min_id</code> system in order to keep the old numerical values of already existing tasks but this time with a breadth-first type algorithm.</p> <p></p>"},{"location":"wip/#end-of-sequence-commuteselect","title":"End-of-sequence (<code>commute</code>/<code>select</code>)","text":"<p>Currently a sequence may not end with a switcher task (<code>commute</code> or <code>select</code>),  this is problematic for pipelines as this means that individual stages cannot  have a commute as their last task. This would require modifications to the  <code>last_subsequence()</code> method, as an end-of-sequence commute would still have a  children.</p>"},{"location":"wip/#example","title":"Example","text":"<p>As an example, let's try to divide the following sequence into 3 stages</p> <pre><code>graph LR;\nA(SS 1)-.-&gt;B(SS select);\nB(SS select)--&gt;C(SS 2);\nC(SS 2)--&gt;F(SS commute);\nF(SS commute)-.-&gt;E(SS 3);\nE(SS 3)-.-&gt;B(SS select);\n    F(SS commute)-.-&gt;G(SS 4);</code></pre> Stage 1Stage 2Stage 3 <pre><code>graph LR;\nA(SS1);</code></pre> <pre><code>graph LR;\nB(SS select)--&gt;C(SS 2);\nC(SS 2)--&gt;F(SS commute);\nF(SS commute)-.-&gt;E(SS 3);\nE(SS 3)-.-&gt;B(SS select);</code></pre> <pre><code>graph LR;\nG(SS 4);</code></pre> <p>With our current implementation of the DFS, Stage 2 technically has no final sub-sequence as every single node has atleast one child thus making the  insertion of push tasks impossible. A solution would be to introduce a fake task  after each commute on their last path during pipeline creations.</p>"}]}